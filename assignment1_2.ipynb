{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b6c2c3-772e-40d4-b7a5-f9ca4e7c85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.8 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/11.8 MB 1.7 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/11.8 MB 1.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/11.8 MB 1.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.3/11.8 MB 1.3 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/11.8 MB 1.8 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/11.8 MB 1.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/11.8 MB 2.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.1/11.8 MB 2.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.9/11.8 MB 4.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.2/11.8 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.0/11.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.9/11.8 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.3/11.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.9/11.8 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.4/11.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.7/11.8 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.2/11.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/11.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.9/11.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.3/11.8 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.0/11.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.8/11.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.8 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.9/11.8 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/11.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.2/11.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/183.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 183.0/183.0 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.4/122.4 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  624.6/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  624.6/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 0.9/1.5 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 18.5 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.3/50.3 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading blis-1.2.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.9/6.3 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.6/6.3 MB 20.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.4/6.3 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.3/6.3 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.9/6.3 MB 17.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.3 MB 16.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.6/6.3 MB 17.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.3 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 15.4 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.6/5.4 MB 19.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.6/5.4 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.1/5.4 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.4 MB 17.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.6/5.4 MB 17.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.2/5.4 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.1/5.4 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "   ---------------------------------------- 0.0/150.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 150.8/150.8 kB ? eta 0:00:00\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 shellingham-1.5.4 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c18572-88d4-4aba-9b7e-a653b9769d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optree>=0.13.0\n",
      "  Downloading optree-0.14.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.6 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 10.2/48.6 kB ? eta -:--:--\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/48.6 kB 165.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.7/48.6 kB 25.2 kB/s eta 0:00:01\n",
      "     -------------------------------- ------ 41.0/48.6 kB 26.9 kB/s eta 0:00:01\n",
      "     --------------------------------------- 48.6/48.6 kB 31.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from optree>=0.13.0) (4.12.2)\n",
      "Downloading optree-0.14.0-cp312-cp312-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/299.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/299.6 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/299.6 kB 262.6 kB/s eta 0:00:02\n",
      "   --- ----------------------------------- 30.7/299.6 kB 262.6 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 41.0/299.6 kB 219.4 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 61.4/299.6 kB 273.8 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/299.6 kB 309.1 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 112.6/299.6 kB 328.2 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/299.6 kB 328.4 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 143.4/299.6 kB 355.0 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/299.6 kB 361.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/299.6 kB 380.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 225.3/299.6 kB 382.6 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 235.5/299.6 kB 379.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/299.6 kB 212.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 276.5/299.6 kB 179.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 276.5/299.6 kB 179.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  297.0/299.6 kB 178.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 299.6/299.6 kB 178.0 kB/s eta 0:00:00\n",
      "Installing collected packages: optree\n",
      "  Attempting uninstall: optree\n",
      "    Found existing installation: optree 0.12.1\n",
      "    Uninstalling optree-0.12.1:\n",
      "      Successfully uninstalled optree-0.12.1\n",
      "Successfully installed optree-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"optree>=0.13.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7646bd-f1f5-46ee-bd95-67fa77190b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5337ba0a-f41f-443e-b82c-4546e9e76917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Error with downloaded zip file\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download resources for NLTK\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d3eaf5-c79e-4dc4-a071-eb16a724826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4804df-d6b0-49d3-859c-7c155ad2bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e53572-88fa-49e3-9e89-25cae88c45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NLTK Implementation ###\n",
    "# Tokenization\n",
    "nltk_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf30813-304e-470f-9cbc-d484b2fb8f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Output: ['natural', 'language', 'processing', '(', 'nlp', ')', 'machine', 'learning', 'technology', 'give', 'computer', 'ability', 'interpret', ',', 'manipulate', ',', 'comprehend', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "# Stopword Removal & Lemmatization\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk_processed = [lemmatizer.lemmatize(word.lower()) for word in nltk_tokens if word.lower() not in stop_words]\n",
    "\n",
    "print(\"NLTK Output:\", nltk_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04da03d-415d-4ce6-87ff-899255d8444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 165.2 kB/s eta 0:01:18\n",
      "     --------------------------------------- 0.0/12.8 MB 163.8 kB/s eta 0:01:18\n",
      "     --------------------------------------- 0.0/12.8 MB 196.9 kB/s eta 0:01:05\n",
      "     --------------------------------------- 0.1/12.8 MB 252.2 kB/s eta 0:00:51\n",
      "     --------------------------------------- 0.1/12.8 MB 364.4 kB/s eta 0:00:35\n",
      "      -------------------------------------- 0.2/12.8 MB 499.5 kB/s eta 0:00:26\n",
      "      -------------------------------------- 0.2/12.8 MB 573.4 kB/s eta 0:00:22\n",
      "      -------------------------------------- 0.3/12.8 MB 681.0 kB/s eta 0:00:19\n",
      "     - ------------------------------------- 0.5/12.8 MB 982.5 kB/s eta 0:00:13\n",
      "     - ------------------------------------- 0.5/12.8 MB 983.0 kB/s eta 0:00:13\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 2.0/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.1/12.8 MB 2.8 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.6/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.0/12.8 MB 5.4 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 5.7 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.4/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.8/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 7.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 11.0/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.5/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 12.1/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 13.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 13.4 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1e77bb-bded-4e98-bd65-a1939d7c7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### spaCy Implementation ###\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564c2d0a-f441-466f-b45d-9dff4b74f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Output: ['natural', 'language', 'processing', '(', 'nlp', ')', 'machine', 'learn', 'technology', 'give', 'computer', 'ability', 'interpret', ',', 'manipulate', ',', 'comprehend', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization, Stopword Removal, Lemmatization\n",
    "spacy_processed = [token.lemma_.lower() for token in doc if not token.is_stop]\n",
    "\n",
    "print(\"spaCy Output:\", spacy_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46daa5-8f3a-406d-a51b-b7bbebb33aa0",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER) with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f174c001-2991-4ea6-8042-7bac8f40d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "Zhang Yiming - PERSON\n",
      "US$45.6 billion - MONEY\n",
      "October 2024 - DATE\n",
      "Forbes - ORG\n",
      "US$43.1 billion - MONEY\n",
      "Bloomberg Billionaires Index - ORG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zhang Yiming\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is one of the richest individuals in the world, with an estimated net worth of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US$45.6 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " as of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    October 2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", according to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Forbes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US$43.1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " according to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bloomberg Billionaires Index\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "text = \"Zhang Yiming is one of the richest individuals in the world, with an estimated net worth of US$45.6 billion as of October 2024, according to Forbes and US$43.1 billion according to Bloomberg Billionaires Index.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract Named Entities\n",
    "print(\"Named Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} - {ent.label_}\")\n",
    "\n",
    "# Visualize Entities\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82ed7e-1ad5-4c9c-80e5-7f17b42546fe",
   "metadata": {},
   "source": [
    "## Text Vectorization using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad0f4e19-6676-46f1-816e-14f039dd9e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.4 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 30.7/44.4 kB 262.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/44.4 kB 219.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.4/44.4 kB 218.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.7 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.1/9.7 MB 1.3 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/9.7 MB 1.3 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/9.7 MB 1.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/9.7 MB 1.3 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.5/9.7 MB 1.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/9.7 MB 1.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.9/9.7 MB 2.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.5/9.7 MB 3.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.0/9.7 MB 4.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/9.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.7 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.5/9.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.0/9.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.5/9.7 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.3/9.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.0/9.7 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.7/9.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.6/9.7 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.7 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.8/9.7 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.3/9.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "   ---------------------------------------- 0.0/464.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 464.1/464.1 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "   ---------------------------------------- 0.0/303.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 303.8/303.8 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.9/2.4 MB 27.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.28.1 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.48.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b074ad81-8d32-48a1-ba66-0dc50911c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([1, 19, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Sample sentence\n",
    "text = \"Natural language processing is a collection of computational techniques\\\n",
    "for automatic analysis and representation of human languages\"\n",
    "\n",
    "# Tokenization\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Extract hidden states\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get embeddings (last hidden state)\n",
    "embeddings = outputs.last_hidden_state\n",
    "print(\"Embedding shape:\", embeddings.shape)  # (batch_size, sequence_length, hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e7138-49ba-4efd-a0c8-3e2062bcf54b",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f919d063-2d27-42d6-b046-fd14d8a6d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 217.9 kB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.1/1.7 MB 297.7 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.1/1.7 MB 374.1 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.2/1.7 MB 546.6 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 623.6 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.7 MB 791.9 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.9/1.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.5.0\n",
      "    Uninstalling keras-3.5.0:\n",
      "      Successfully uninstalled keras-3.5.0\n",
      "Successfully installed keras-2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.13.0 requires keras>=3.2.0, but you have keras 2.11.0 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires keras>=3.5.0, but you have keras 2.11.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d64007-8a00-4f0f-9839-b72ddb753a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The battery life was a bit disappointing. => {'label': 'NEGATIVE', 'score': 0.9996581077575684}\n",
      "Sentence: The movie was okay, but not great. => {'label': 'NEGATIVE', 'score': 0.9984203577041626}\n",
      "Sentence: I am happy with the purchase. => {'label': 'POSITIVE', 'score': 0.9998704195022583}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress warnings \n",
    "tf.get_logger().setLevel('ERROR')  # Suppress logs from TensorFlow\n",
    "\n",
    "# Load  pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "sentences = [\n",
    "    \"The battery life was a bit disappointing.\",\n",
    "    \"The movie was okay, but not great.\",\n",
    "    \"I am happy with the purchase.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiment\n",
    "results = sentiment_pipeline(sentences)\n",
    "\n",
    "# Results\n",
    "for sentence, result in zip(sentences, results):\n",
    "    print(f\"Sentence: {sentence} => {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d9f621-293c-4a08-b889-6d69c7c5aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Asus\\anaconda3\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER -> Sentence: 'The battery life was a bit disappointing.' => {'neg': 0.39, 'neu': 0.61, 'pos': 0.0, 'compound': -0.4939}\n",
      "VADER -> Sentence: 'The movie was okay, but not great.' => {'neg': 0.408, 'neu': 0.459, 'pos': 0.133, 'compound': -0.6112}\n",
      "VADER -> Sentence: 'I am happy with the purchase.' => {'neg': 0.0, 'neu': 0.519, 'pos': 0.481, 'compound': 0.5719}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze sentiment with VADER\n",
    "for sentence in sentences:\n",
    "    vader_score = sia.polarity_scores(sentence)\n",
    "    print(f\"VADER -> Sentence: '{sentence}' => {vader_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1172139-7a46-4884-92d0-e7ac2f034fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
